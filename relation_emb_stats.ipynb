{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3f412c5",
   "metadata": {},
   "source": [
    "A notebook for data manipulation before contrastive training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6d172",
   "metadata": {},
   "source": [
    "## Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0239339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3506ab",
   "metadata": {},
   "source": [
    "#### Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf2c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_rel_dict(path):\n",
    "\n",
    "    with open(path) as f:\n",
    "        data = f.read()\n",
    "\n",
    "    rel_dict = {}\n",
    "    for r in data.split(\"\\n\")[1:-1]:\n",
    "        rel_id, rel = re.split(r\"\\((\\d+)\\)\",r)[1:]\n",
    "        rel_dict[int(rel_id)] = rel.strip()\n",
    "\n",
    "    return rel_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_labelstudio(path: str, relation_mapping) -> pd.DataFrame:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        dataset = json.load(file)\n",
    "        \n",
    "    ls_tuples = []    \n",
    "    for entry in dataset:\n",
    "        annotations = entry.get(\"annotations\", [])\n",
    "        data = entry.get(\"data\", {})\n",
    "\n",
    "        sentence = data.get(\"sentence\", \"\")\n",
    "        paper_id = data.get(\"paper_id\")\n",
    "        sentence_id = data.get(\"sentence_id\")\n",
    "        # entity_types_mapping = {e[\"id\"]: e[\"value\"][\"labels\"] for e in annotation.get(\"result\", []) if e[\"type\"] == \"labels\"}\n",
    "        \n",
    "        for annotation in annotations:\n",
    "            results = annotation.get(\"result\", [])\n",
    "            entities = {e[\"id\"]: e[\"value\"] for e in results if e[\"type\"] == \"labels\"}\n",
    "            relations = [r for r in results if r[\"type\"] == \"relation\"]\n",
    "\n",
    "            for relation in relations:\n",
    "                from_id = relation[\"from_id\"]\n",
    "                to_id = relation[\"to_id\"]\n",
    "                direction = relation[\"direction\"]\n",
    "                relation_type = relation.get(\"labels\", [\"\"])[0] or \"0\"\n",
    "                relation_name = relation_mapping.get(int(relation_type), \"\")\n",
    "\n",
    "                # Get entity spans\n",
    "                e1_value = entities.get(from_id if direction == \"right\" else to_id, {})\n",
    "                e2_value = entities.get(to_id if direction == \"right\" else from_id, {})\n",
    "\n",
    "                e1_text = e1_value.get(\"text\", \"\")\n",
    "                e2_text = e2_value.get(\"text\", \"\")\n",
    "\n",
    "                e1_type = e1_value.get(\"labels\", \"\")[0]\n",
    "                e2_type = e2_value.get(\"labels\", \"\")[0]\n",
    "                \n",
    "                e1_start_pos = e1_value.get(\"start\", 0)\n",
    "                e1_end_pos = e1_value.get(\"end\", 0)\n",
    "                \n",
    "                e2_start_pos = e2_value.get(\"start\", 0)\n",
    "                e2_end_pos = e2_value.get(\"end\", 0)\n",
    "\n",
    "                ls_tuples.append({\n",
    "                    'sent': sentence,\n",
    "                    'r': relation_name,\n",
    "                    'e1': e1_text,\n",
    "                    'e1_t': e1_type,\n",
    "                    'e1_start_pos': e1_start_pos,\n",
    "                    'e1_end_pos': e1_end_pos,\n",
    "                    'e2': e2_text,\n",
    "                    'e2_t': e2_type,\n",
    "                    'e2_start_pos': e2_start_pos,\n",
    "                    'e2_end_pos': e2_end_pos,\n",
    "                    'paper_id': paper_id,\n",
    "                    'sentence_id': sentence_id\n",
    "                })\n",
    "\n",
    "                # If bidirectional, add the reverse too\n",
    "                if direction == \"undirected\":\n",
    "                    ls_tuples.append({\n",
    "                        'sent': sentence,\n",
    "                        'r': relation_name,\n",
    "                        'e1': e2_text,\n",
    "                        'e1_t': e2_type,\n",
    "                        'e1_start_pos': e2_start_pos,\n",
    "                        'e1_end_pos': e2_end_pos,\n",
    "                        'e2': e1_text,\n",
    "                        'e2_t': e1_type,\n",
    "                        'e2_start_pos': e1_start_pos,\n",
    "                        'e2_end_pos': e1_end_pos,\n",
    "                        'paper_id': paper_id,\n",
    "                        'sentence_id': sentence_id\n",
    "                    })\n",
    "\n",
    "    return pd.DataFrame(ls_tuples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096b521",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37df977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_filepath = \"DATA/project-6-at-2025-06-24-06-31-0c74618b.json\"\n",
    "rel_dictpath = \"/home/p0l3/RAD/DROP/RELdata_simple.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a56b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_mapping = load_rel_dict(rel_dictpath)\n",
    "df = parse_labelstudio(ls_filepath, relation_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f1d0b",
   "metadata": {},
   "source": [
    "## Contrastive Dataset Creation\n",
    "\n",
    "**Note:** For a more in-depth analysis of the data, go to original notebook: [relation_emb_stats](https://github.com/P0L3/rel_dis/blob/main/REL_DIS/relation_emb_stats.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85282c0",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d3899cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pos_level_1_pairs(df):\n",
    "    \"\"\"Hardest Positive: Same r, same e1_t, same e2_t.\"\"\"\n",
    "    grouped = df.groupby(['r', 'e1_t', 'e2_t'])\n",
    "    pairs = defaultdict(list)\n",
    "    for _, group in grouped:\n",
    "        indices = group.index.tolist()\n",
    "        if len(indices) > 1:\n",
    "            for i in indices:\n",
    "                pairs[i].extend([j for j in indices if i != j])\n",
    "    return dict(pairs)\n",
    "\n",
    "def compute_pos_level_2_pairs(df):\n",
    "    \"\"\"Medium Positive: Same r, one entity type match (XOR).\"\"\"\n",
    "    grouped = df.groupby('r')\n",
    "    pairs = defaultdict(list)\n",
    "    for _, group in grouped:\n",
    "        for i, row_i in group.iterrows():\n",
    "            for j, row_j in group.iterrows():\n",
    "                if i == j: continue\n",
    "                if (row_i['e1_t'] == row_j['e1_t']) ^ (row_i['e2_t'] == row_j['e2_t']):\n",
    "                    pairs[i].append(j)\n",
    "    return dict(pairs)\n",
    "\n",
    "def compute_pos_level_3_pairs(df):\n",
    "    \"\"\"Easiest Positive: Same r, different entity types.\"\"\"\n",
    "    grouped = df.groupby('r')\n",
    "    pairs = defaultdict(list)\n",
    "    for _, group in grouped:\n",
    "        for i, row_i in group.iterrows():\n",
    "            for j, row_j in group.iterrows():\n",
    "                if i == j: continue\n",
    "                if (row_i['e1_t'] != row_j['e1_t']) and (row_i['e2_t'] != row_j['e2_t']):\n",
    "                    pairs[i].append(j)\n",
    "    return dict(pairs)\n",
    "    \n",
    "def compute_neg_level_3_pairs(df):\n",
    "    \"\"\"Easiest Negative: Different r, same entity types.\"\"\"\n",
    "    df_with_idx = df.reset_index()\n",
    "    merged = pd.merge(df_with_idx, df_with_idx, on=['e1_t', 'e2_t'])\n",
    "    filtered = merged[(merged.r_x != merged.r_y) & (merged.index_x != merged.index_y)]\n",
    "    return filtered.groupby('index_x')['index_y'].apply(list).to_dict()\n",
    "\n",
    "def compute_neg_level_2_pairs(df):\n",
    "    \"\"\"Medium Negative: Different r, one entity type match.\"\"\"\n",
    "    df_with_idx = df.reset_index().rename(columns={'index': 'idx'})\n",
    "    m1 = pd.merge(df_with_idx, df_with_idx, on='e1_t')\n",
    "    cond1 = (m1.r_x != m1.r_y) & (m1.e2_t_x != m1.e2_t_y) & (m1.idx_x != m1.idx_y)\n",
    "    p1 = m1[cond1][['idx_x', 'idx_y']]\n",
    "    m2 = pd.merge(df_with_idx, df_with_idx, on='e2_t')\n",
    "    cond2 = (m2.r_x != m2.r_y) & (m2.e1_t_x != m2.e1_t_y) & (m2.idx_x != m2.idx_y)\n",
    "    p2 = m2[cond2][['idx_x', 'idx_y']]\n",
    "    all_pairs = pd.concat([p1, p2]).drop_duplicates()\n",
    "    return all_pairs.groupby('idx_x')['idx_y'].apply(list).to_dict()\n",
    "\n",
    "def compute_neg_level_1_pairs(df):\n",
    "    \"\"\"Hardest Negative: Different r, different entity types.\"\"\"\n",
    "    df_with_idx = df.reset_index().rename(columns={'index': 'idx'})\n",
    "    df_with_idx['key'] = 1\n",
    "    merged = pd.merge(df_with_idx, df_with_idx, on='key').drop('key', axis=1)\n",
    "    condition = (\n",
    "        (merged.r_x != merged.r_y) &\n",
    "        (merged.e1_t_x != merged.e1_t_y) &\n",
    "        (merged.e2_t_x != merged.e2_t_y) &\n",
    "        (merged.idx_x != merged.idx_y)\n",
    "    )\n",
    "    filtered = merged[condition]\n",
    "    return filtered.groupby('idx_x')['idx_y'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe17b6",
   "metadata": {},
   "source": [
    "### Dataframe construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8629e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairs for all 6 levels...\n",
      "  - Computing pos_level_1...\n",
      "  - Computing pos_level_2...\n",
      "  - Computing pos_level_3...\n",
      "  - Computing neg_level_1...\n",
      "  - Computing neg_level_2...\n",
      "  - Computing neg_level_3...\n",
      "\n",
      "--- Augmented DataFrame ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Computing pairs for all 6 levels...\")\n",
    "\n",
    "level_funcs = {\n",
    "    'pos_level_1': compute_pos_level_1_pairs,\n",
    "    'pos_level_2': compute_pos_level_2_pairs,\n",
    "    'pos_level_3': compute_pos_level_3_pairs,\n",
    "    'neg_level_1': compute_neg_level_1_pairs,\n",
    "    'neg_level_2': compute_neg_level_2_pairs,\n",
    "    'neg_level_3': compute_neg_level_3_pairs,\n",
    "}\n",
    "\n",
    "for col_name, func in level_funcs.items():\n",
    "    print(f\"  - Computing {col_name}...\")\n",
    "    pair_dict = func(df)\n",
    "    \n",
    "    # --- CORRECTED LOGIC ---\n",
    "    # Step 1: Create the new column. It will contain lists and NaN values.\n",
    "    # pandas correctly aligns the dictionary keys with the DataFrame index.\n",
    "    df[col_name] = df.index.map(pair_dict)\n",
    "    \n",
    "    # Create the series which contains lists and NaN values\n",
    "    series_with_nans = df.index.map(pair_dict)\n",
    "\n",
    "    # Step 2: Now that df[col_name] is a Series, apply the function to it\n",
    "    df[col_name] = [x if isinstance(x, list) else [] for x in series_with_nans]\n",
    "\n",
    "print(\"\\n--- Augmented DataFrame ---\")\n",
    "# To display the lists properly\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Display the relevant columns\n",
    "display_cols = ['sent'] + list(level_funcs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6d23a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = ls_filepath.replace(\".json\", \"_df.pickle\")\n",
    "df.to_pickle(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d41b31",
   "metadata": {},
   "source": [
    "## Data Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c4ce7",
   "metadata": {},
   "source": [
    "### Data Specification: Pre-computed Contrastive Pairs for Relation Extraction\n",
    "\n",
    "**Version:** 1.2\n",
    "**Date:** June 25, 2025\n",
    "**Contact:** Andrija Poleksić (andrija.poleksic@uniri.hr)\n",
    "\n",
    "#### 1. Overview\n",
    "\n",
    "This document specifies the format for a dataset designed for contrastive learning of sentence representations for relation extraction. The dataset is delivered as a single tabular file (e.g., CSV, Parquet) that can be loaded into a pandas DataFrame.\n",
    "\n",
    "The primary unit of this dataset is a **relation instance**. Each row represents a single semantic relation (`r`) between two entities (`e1`, `e2`)—with their precise character-level positions—found within a source sentence (`sent`).\n",
    "\n",
    "A key feature of this dataset is the pre-computation of six columns (`pos_level_1` through `neg_level_3`). These columns contain lists of indices pointing to other relation instances, categorized by similarity. This structure is purpose-built to facilitate advanced training strategies, such as weighted contrastive loss, where the \"hardness\" of a pair determines the strength of the training signal.\n",
    "\n",
    "#### 2. File Format & Schema\n",
    "\n",
    "The data is structured as a table, typically stored in a `.csv` or `.parquet` file. When loaded, it forms a pandas DataFrame where the **index of the DataFrame serves as the unique ID for each relation instance**.\n",
    "\n",
    "**Schema Definition:**\n",
    "\n",
    "| Column Name     | Data Type             | Description                                                                                                                              | Example from Data                                                              |\n",
    "| :-------------- | :-------------------- | :--------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------- |\n",
    "| `index`         | Integer (Implicit)    | The unique identifier for each relation instance. All `pos_` and `neg_` level columns contain lists of these index values.                  | `0`                                                                            |\n",
    "| `sent`          | String                | The full source sentence from which the relation was extracted. May be duplicated across rows if a sentence contains multiple relations. | `\"The marine algal toxin domoic acid is an important threat...\"`              |\n",
    "| `r`             | String                | The relation phrase or label connecting the two entities.                                                                                | `\"is a threat\"`                                                                |\n",
    "| `e1`            | String                | The text of the first entity (subject) in the relation.                                                                                  | `\"domoic acid\"`                                                                |\n",
    "| `e1_t`          | String                | The designated type of the first entity.                                                                                                 | `\"Chemical\"`                                                                   |\n",
    "| `e1_start_pos`| Integer             | The start character index of `e1` within `sent` (inclusive).                                                                         | `23`                                                                       |\n",
    "| `e1_end_pos`  | Integer             | The end character index of `e1` within `sent` (exclusive).                                                                           | `34`                                                                       |\n",
    "| `e2`            | String                | The text of the second entity (object) in the relation.                                                                                  | `\"marine mammal health\"`                                                       |\n",
    "| `e2_t`          | String                | The designated type of the second entity.                                                                                                | `\"Other\"`                                                                      |\n",
    "| `e2_start_pos`| Integer             | The start character index of `e2` within `sent` (inclusive).                                                                         | `61`                                                                       |\n",
    "| `e2_end_pos`  | Integer             | The end character index of `e2` within `sent` (exclusive).                                                                           | `81`                                                                       |\n",
    "| `paper_id`      | Integer               | An identifier for the source document or paper.                                                                                          | `10167`                                                                        |\n",
    "| `sentence_id`   | Integer               | An identifier for the sentence within its source document.                                                                               | `0`                                                                            |\n",
    "| `pos_level_1`   | List of Integers      | A list of indices pointing to \"Hardest Positive\" examples.                                                                               | `[449]`                                                                        |\n",
    "| `pos_level_2`   | List of Integers      | A list of indices pointing to \"Medium Positive\" examples.                                                                                | `[1202]`                                                                       |\n",
    "| `pos_level_3`   | List of Integers      | A list of indices pointing to \"Easiest Positive\" examples.                                                                               | `[2017]`                                                                       |\n",
    "| `neg_level_1`   | List of Integers      | A list of indices pointing to \"Easiest Negative\" examples.                                                                               | `[5, 8, 9, 10, ...]`                                                           |\n",
    "| `neg_level_2`   | List of Integers      | A list of indices pointing to \"Medium Negative\" examples.                                                                                | `[1, 2, 3, 4, ...]`                                                            |\n",
    "| `neg_level_3`   | List of Integers      | A list of indices pointing to \"Hardest Negative\" examples.                                                                               | `[11, 52, 119, ...]`                                                           |\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Definitions of Similarity Levels\n",
    "\n",
    "The categorization of positive and negative levels determines the desired strength of the training signal. **\"Harder\" examples are those that should be pulled closest (for positives) or pushed furthest away (for negatives) during training.**\n",
    "\n",
    "##### 3.1. Positive Levels (Same Relation)\n",
    "A \"positive\" pair always shares the **same `r`** (relation) as the anchor. The hardness level defines how close their embeddings should become.\n",
    "\n",
    "| Level         | Condition for Inclusion                                          | Hardness Interpretation                                                                |\n",
    "| :------------ | :--------------------------------------------------------------- | :------------------------------------------------------------------------------------- |\n",
    "| `pos_level_1` | **Same** `r`, **Same** `e1_t`, **Same** `e2_t`                     | **Hardest Positive**. Structurally identical; should be pulled very close in the embedding space. |\n",
    "| `pos_level_2` | **Same** `r`, one matching entity type, one different entity type. | **Medium Positive**. Shares a core context; should be pulled moderately close.         |\n",
    "| `pos_level_3` | **Same** `r`, **Different** `e1_t`, **Different** `e2_t`           | **Easiest Positive**. Shares only the abstract relation; requires a standard \"pull\" force. |\n",
    "\n",
    "##### 3.2. Negative Levels (Different Relation)\n",
    "A \"negative\" pair always has a **different `r`** (relation) from the anchor. The hardness level defines how far their embeddings should be pushed apart.\n",
    "\n",
    "| Level         | Condition for Inclusion                                            | Hardness Interpretation                                                              |\n",
    "| :------------ | :----------------------------------------------------------------- | :----------------------------------------------------------------------------------- |\n",
    "| `neg_level_1` | **Different** `r`, **Same** `e1_t`, **Same** `e2_t`                  | **Easiest Negative**. Semantically confusable; requires a small \"push\" just beyond the decision margin. |\n",
    "| `neg_level_2` | **Different** `r`, one matching entity type, one different entity type. | **Medium Negative**. Represents a moderate level of dissimilarity, requiring an intermediate push-away force. |\n",
    "| `neg_level_3` | **Different** `r`, **Different** `e1_t`, **Different** `e2_t`        | **Hardest Negative**. Structurally and semantically very different; should be pushed furthest away. |\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Example Row\n",
    "\n",
    "| Field           | Value                                                                                         |\n",
    "| :-------------- | :-------------------------------------------------------------------------------------------- |\n",
    "| **index**       | `0`                                                                                           |\n",
    "| **sent**        | `\"The marine algal toxin domoic acid is an important threat to marine mammal health...\"`        |\n",
    "| **r**           | `\"is a threat\"`                                                                               |\n",
    "| **e1**          | `\"domoic acid\"`                                                                               |\n",
    "| **e1_t**        | `\"Chemical\"`                                                                                  |\n",
    "| **e1_start_pos**| `23`                                                                                          |\n",
    "| **e1_end_pos**  | `34`                                                                                          |\n",
    "| **e2**          | `\"marine mammal health\"`                                                                      |\n",
    "| **e2_t**        | `\"Other\"`                                                                                     |\n",
    "| **e2_start_pos**| `61`                                                                                          |\n",
    "| **e2_end_pos**  | `81`                                                                                          |\n",
    "| **paper_id**    | `10167`                                                                                       |\n",
    "| **sentence_id** | `0`                                                                                           |\n",
    "| **pos_level_1** | `[449]`                                                                                       |\n",
    "| **pos_level_2** | `[]`                                                                                          |\n",
    "| **pos_level_3** | `[2017]`                                                                                      |\n",
    "| **neg_level_1** | `[5, 8, 9, 10, ...]`                                                                          |\n",
    "| **neg_level_2** | `[1, 2, 3, 4, ...]`                                                                           |\n",
    "| **neg_level_3** | `[11, 52, 119, ...]`                                                                          |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
